{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0683e728-3f54-4f05-8f13-545f6d2065cb",
   "metadata": {},
   "source": [
    "# BTC Price Prediction<br>LSTM Model\n",
    "## Import Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc091778-1f21-46cb-b71c-194ca4300e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4500649-cd67-43a9-bd1b-23dc4d1e68d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the btc price data from yahoo finance\n",
    "df = yf.download('BTC-USD', start='2017-01-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2f3e04-a60a-40fb-860c-c8cbe7c4492e",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac543ad-99ee-4031-93c5-46d352c1b10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546cf638-d041-4c98-aa28-bbcc9a87abcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # Lookign at what the dataset contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cc3f7e-1594-47b7-a448-15614c398b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"Close\"]] # Selecting the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0c8ba3-30cb-4d56-8a70-e135607994b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() # Seeing what the target variable is like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453285b7-f01b-4c16-874d-1458888ff64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploting the target variable\n",
    "plt.figure(1, figsize=(16,6))\n",
    "plt.plot(df.Close)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414e0c84-5524-4eee-8452-dfc36acebc41",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a3cc1f-0357-40cb-9c7d-0a2f5ed853b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Returns\"] = df.Close.pct_change() # Adding a feature for returns of each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bafa52f-51da-44fb-834b-46794325e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Log_Returns\"] = np.log(1 + df[\"Returns\"]) # Taking the log of returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95d6a3c-8500-4e1e-8de7-e94be8a79a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Log retuens to see if the mean is consistant throughout the data\n",
    "plt.figure(1, figsize=(16,4))\n",
    "plt.plot(df.Log_Returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a28a270-92fa-44fd-91f6-89ca7c756876",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True) # Dropping missing values\n",
    "X = df[[\"Close\", \"Log_Returns\"]].values # Settign the features that are going to be used for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d2d180-b093-4108-ae90-f3a46b51c49b",
   "metadata": {},
   "source": [
    "## Test train Split, Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ff0550-ca8d-4ec2-b2d4-367d1f702136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8e6583-8378-4678-b1f7-2c518736bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range = (0, 1)).fit(X) # Setting up the scaler for the chosen features and fitting them to the scaler\n",
    "X_scaled = scaler.transform(X) # Transforming the scaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0abf0f-b183-4198-83c9-af20b4c764e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled[0] # Making sure they scaled correctly and have the correct datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6c6034-5a50-4752-b66f-11cc949517ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the labels for the model.\n",
    "y = [x[0] for x in X_scaled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5bfa05-9573-4079-b372-e74f93556f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the split for training and testing sets and checking how many will be splt into the training data.\n",
    "split = int(len(X_scaled) * 0.8)\n",
    "print(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9a9783-2414-45e4-baf7-63f8fa550eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_scaled[:split] # Feature training set\n",
    "X_test = X_scaled[split: len(X_scaled)] # Feature testing set\n",
    "y_train = y[:split] # Label training set\n",
    "y_test = y[split : len(y)] # Label testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cc1a97-0059-471f-b777-31a6f8bf5e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure that the feature and labels for both sets are equal. Length of returns = Length of close\n",
    "assert len(X_train) == len(y_train)\n",
    "assert len(X_test) == len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b4d66c-f473-4ea4-b732-25b58238462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalizing the test, train, split\n",
    "# Converting into tensorflow readable arrays\n",
    "n = 60\n",
    "Xtrain = []\n",
    "ytrain = []\n",
    "Xtest = []\n",
    "ytest = []\n",
    "for i in range(n, len(X_train)):\n",
    "    Xtrain.append(X_train[i - n : i, : X_train.shape[1]])\n",
    "    ytrain.append(y_train[i]) # predict next record\n",
    "for i in range(n, len(X_test)):\n",
    "    Xtest.append(X_test[i - n : i, : X_test.shape[1]])\n",
    "    ytest.append(y_test[i]) # predict next record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdeada8-be9f-4191-a448-e05cfadd3839",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc843c53-0b35-472e-9049-2d8975ec4391",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8786fdfb-3923-40d1-b9e8-e60fc3931205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a validation set\n",
    "val = np.array(ytrain[0])\n",
    "val = np.c_[val, np.zeros(val.shape)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0e093e-7843-43de-85ee-ed7db2693ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the Validation set \n",
    "scaler.inverse_transform(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f74a3b3-83cc-40cc-bd62-af39af288a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping arrays to fit in LSTM Model\n",
    "Xtrain, ytrain = (np.array(Xtrain), np.array(ytrain))\n",
    "Xtrain = np.reshape(Xtrain, (Xtrain.shape[0], Xtrain.shape[1], Xtrain.shape[2]))\n",
    "\n",
    "Xtest, ytest = (np.array(Xtest), np.array(ytest))\n",
    "Xtest = np.reshape(Xtest, (Xtest.shape[0], Xtest.shape[1], Xtest.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b681b9-0437-4dff-b49e-3f159045ea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to make sure that shape of each Feature and Label set are correct\n",
    "print(Xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(\"---\")\n",
    "print(Xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6e3d03-cb44-4929-83b6-b15aff989a90",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b41b27-a2b9-4c00-8384-c36c5cb19a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bb0487-8988-4c0e-9f19-20e9a6361e88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential() # Setting up a sequential model\n",
    "model.add(LSTM(4, input_shape=(Xtrain.shape[1], Xtrain.shape[2]))) # Adding the LSTM layer to the model\n",
    "model.add(Dense(1)) # Adding a dense layer to the model\n",
    "model.compile(loss=\"mean_squared_error\", optimizer='adam') # Compiling the model and getting it ready for building\n",
    "model.fit(Xtrain, ytrain, epochs=250, validation_data=(Xtest, ytest), batch_size=8, verbose=1) # Fitting the data to the model and building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dc2239-ff48-4909-b208-b4f2903a8a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary() # Checkign what the model produced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3e35e4-c4fc-4545-991b-204d9ae41821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up predictions for the model\n",
    "trainPredict = model.predict(Xtrain)\n",
    "testPredict = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce67870-98aa-45e5-91c2-5b894643e567",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = np.c_[trainPredict, np.zeros(trainPredict.shape)]\n",
    "testPredict = np.c_[testPredict, np.zeros(testPredict.shape)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70294188-10d0-48bd-b8ca-a0182214adc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainPredict = [x[0] for x in trainPredict]\n",
    "\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testPredict = [x[0] for x in testPredict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539e76f7-5cf1-4147-9477-d5b4df3f5c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing what the model predicted\n",
    "print(trainPredict[:5])\n",
    "print(testPredict[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c781bad-efae-4cbe-aed9-6571b0e30d44",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279808a4-9628-4118-a6ed-ffb4b08539a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e03ff53-77ab-413b-a717-7e8d2aaa5291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using RMSE to grade the model/See how well it performed\n",
    "trainScore = mean_squared_error([x[0][0] for x in Xtrain], trainPredict, squared=False)\n",
    "print(\"Train Score: %.2f RMSE\" % (trainScore))\n",
    "\n",
    "testScore = mean_squared_error([x[0][0] for x in Xtest], testPredict, squared=False)\n",
    "print(\"Test Score: %.2f RMSE\" % (testScore))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
